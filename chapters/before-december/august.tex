\chapter{August}

Things discussed in meeting:
	
	Analyzed congestion and why is it sub linear ?
	
	In SHIA leaves verify their values with final results not with intermediate results. 
	But in surveillance application data is compared with some base value in such network intermediate values are important. 

	Analyze the protocol with Digital signatures. How many signatures do we need ?

	Analyze properties of commitment tree.

\textbf{Definitions}

A \textbf{direct data injection attack} occurs when an attacker
modifies the data readings reported by the nodes under its direct
control, under the constraint that only legal readings in [0, r] are
reported.

An aggregation algorithm is \textbf{optimally secure} if, by
tampering with the aggregation process, an adversary is unable to
induce the querier to accept any aggregation result which is not
already achievable by direct data injection.

For example,
if A is an aggregator and it receives one reading from B. So, A needs to aggregate two values one of its own and the other is B's value. Suppose, maximum allowed value is 40. A0 = 10, B0 = 20. A1 = 30. A1 <= 80. If A reports any value out of that range it will get caught and any cheating within the range falls under direct data injection attack.

\textbf{Congestion}

As a metric for communication overhead, we consider node congestion,
which is the worst case communication load on any single
sensor node during the algorithm. Congestion is a commonly
used metric in ad-hoc networks since it measures how quickly the
heaviest-loaded nodes will exhaust their batteries [6, 12]. Since the
heaviest-loaded nodes are typically the nodes which are most essential
to the connectivity of the network (e.g., the nodes closest to
the base station), their failure may cause the network to partition
even though other sensor nodes in the network may still have high
battery levels. A lower communication load on the heaviest-loaded
nodes is thus desirable even if the trade-off is a larger amount of
communication in the network as a whole.

For a lower bound on congestion, consider an unsecured aggregation
protocol where each node sends just a single message to
its parent in the aggregation tree. This is the minimum number
of messages that ensures that each sensor node contributes to the
aggregation result. There is $\Omega(1)$ congestion on each edge on the
aggregation tree, thus resulting in $\Omega(d)$ congestion on the node(s)
with highest degree d in the aggregation tree. The parameter d is
dependent on the shape of the given aggregation tree and can be as
large as $\Theta(n)$ for a single-aggregator topology or as small as $\Theta(1)$ for a balanced aggregation tree. Since we are taking the aggregation
tree topology as an input, we have no control over d. Hence,
it is often more informative to consider per-edge congestion, which
can be independent of the structure of the aggregation tree.

Consider the simplest solution where we omit aggregation altogether
and simply send all data values (encrypted and authenticated)
directly to the base station, which then forwards it to the
querier. This provides perfect data integrity, but induces O(n) congestion
at the nodes and edges nearest the base station. For an algorithm
to be practical, it must cause only sublinear edge congestion.

Our goal is to design an optimally secure aggregation algorithm
with only sublinear edge congestion.


	1. remove complement
	2. variable range